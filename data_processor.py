"""
æˆæ¥­ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã€ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€é›†è¨ˆã‚’è¡Œã†é–¢æ•°ç¾¤
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import io


# ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å¤‰æ›ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆ4ä»¶æ³•ï¼‰
SCORE_MAPPING = {
    # 4ç‚¹ï¼ˆæœ€é«˜è©•ä¾¡ï¼‰
    "ã¨ã¦ã‚‚ãã†æ€ã†": 4,
    "å½“ã¦ã¯ã¾ã‚‹": 4,
    "ã¨ã¦ã‚‚å½“ã¦ã¯ã¾ã‚‹": 4,
    "å¼·ããã†æ€ã†": 4,

    # 3ç‚¹
    "ãã†æ€ã†": 3,
    "ã©ã¡ã‚‰ã‹ã¨ã„ãˆã°ãã†æ€ã†": 3,
    "ã‚„ã‚„å½“ã¦ã¯ã¾ã‚‹": 3,
    "ã©ã¡ã‚‰ã‹ã¨ã„ãˆã°å½“ã¦ã¯ã¾ã‚‹": 3,

    # 2ç‚¹
    "ã‚ã¾ã‚Šãã†æ€ã‚ãªã„": 2,
    "ã©ã¡ã‚‰ã‹ã¨ã„ãˆã°ãã†æ€ã‚ãªã„": 2,
    "ã‚ã¾ã‚Šå½“ã¦ã¯ã¾ã‚‰ãªã„": 2,
    "ã©ã¡ã‚‰ã‹ã¨ã„ãˆã°å½“ã¦ã¯ã¾ã‚‰ãªã„": 2,

    # 1ç‚¹ï¼ˆæœ€ä½è©•ä¾¡ï¼‰
    "æ€ã‚ãªã„": 1,
    "ãã†æ€ã‚ãªã„": 1,
    "å½“ã¦ã¯ã¾ã‚‰ãªã„": 1,
    "å…¨ãå½“ã¦ã¯ã¾ã‚‰ãªã„": 1,
    "å…¨ããã†æ€ã‚ãªã„": 1,
}


# é™¤å¤–ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ åï¼ˆã“ã‚Œã‚‰ã¯è³ªå•é …ç›®ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰
METADATA_COLUMNS = [
    "Id",
    "id",
    "ID",
    "é–‹å§‹æ™‚åˆ»",
    "å®Œäº†æ™‚åˆ»",
    "ãƒ¡ãƒ¼ãƒ«",
    "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹",
    "Email",
    "email",
    "åå‰",
    "æ°å",
    "Name",
    "name",
    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—",
    "Timestamp",
    "timestamp",
]

# å¿…é ˆã‚«ãƒ©ãƒ ï¼ˆç§‘ç›®åè­˜åˆ¥ç”¨ï¼‰
SUBJECT_COLUMN_PATTERNS = [
    "ç§‘ç›®å",
    "ç§‘ç›®",
    "æ•™ç§‘å",
    "æˆæ¥­å",
]

# å‡ºå¸­ç•ªå·ã‚«ãƒ©ãƒ ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
STUDENT_ID_PATTERNS = [
    "å‡ºå¸­ç•ªå·",
    "å­¦ç±ç•ªå·",
    "å­¦ç”Ÿç•ªå·",
]

# è‡ªç”±è¨˜è¿°ã‚«ãƒ©ãƒ ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
FREE_TEXT_PATTERNS = [
    "æ„è¦‹ãƒ»æ„Ÿæƒ³",
    "æ„è¦‹",
    "æ„Ÿæƒ³",
    "ã‚³ãƒ¡ãƒ³ãƒˆ",
    "è‡ªç”±è¨˜è¿°",
    "ãã®ä»–",
    "è¨˜å…¥ã—ã¦ãã ã•ã„",
    "ã”è¨˜å…¥ãã ã•ã„",
]


def convert_to_score(value: str) -> Optional[float]:
    """
    4ä»¶æ³•ã®ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã‚’æ•°å€¤ã‚¹ã‚³ã‚¢ã«å¤‰æ›

    Args:
        value: å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        float: å¤‰æ›å¾Œã®ã‚¹ã‚³ã‚¢ï¼ˆ1-4ï¼‰ã€å¤‰æ›ã§ããªã„å ´åˆã¯None
    """
    if pd.isna(value):
        return None

    # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    value_str = str(value).strip()

    # ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ¤œç´¢
    return SCORE_MAPPING.get(value_str, None)


def detect_subject_column(df: pd.DataFrame) -> Optional[str]:
    """
    ç§‘ç›®åã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡º

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

    Returns:
        str: ç§‘ç›®åã‚«ãƒ©ãƒ åã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
    """
    for col in df.columns:
        for pattern in SUBJECT_COLUMN_PATTERNS:
            if pattern in col:
                return col
    return None


def detect_student_id_column(df: pd.DataFrame) -> Optional[str]:
    """
    å‡ºå¸­ç•ªå·ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡º

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

    Returns:
        str: å‡ºå¸­ç•ªå·ã‚«ãƒ©ãƒ åã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
    """
    for col in df.columns:
        for pattern in STUDENT_ID_PATTERNS:
            if pattern in col:
                return col
    return None


def detect_free_text_column(df: pd.DataFrame) -> Optional[str]:
    """
    è‡ªç”±è¨˜è¿°ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡º

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

    Returns:
        str: è‡ªç”±è¨˜è¿°ã‚«ãƒ©ãƒ åã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
    """
    # ã‚ˆã‚Šå…·ä½“çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é †ã«æ¤œç´¢
    # ï¼ˆã€Œæ„è¦‹ã€ã ã‘ã§ãªãã€Œã”è¨˜å…¥ãã ã•ã„ã€ãªã©ã®å…·ä½“çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å„ªå…ˆï¼‰
    priority_patterns = ["ã”è¨˜å…¥ãã ã•ã„", "è¨˜å…¥ã—ã¦ãã ã•ã„", "æ„è¦‹ãƒ»æ„Ÿæƒ³", "è‡ªç”±è¨˜è¿°"]

    # å„ªå…ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢
    for pattern in priority_patterns:
        for col in df.columns:
            if pattern in col:
                return col

    # ãã®ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢
    for col in df.columns:
        for pattern in FREE_TEXT_PATTERNS:
            if pattern in col and pattern not in priority_patterns:
                return col

    return None


def identify_question_columns(df: pd.DataFrame) -> List[str]:
    """
    è³ªå•é …ç›®ã‚«ãƒ©ãƒ ã‚’è­˜åˆ¥ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ç§‘ç›®åã€å‡ºå¸­ç•ªå·ã€è‡ªç”±è¨˜è¿°ã‚’é™¤å¤–ï¼‰

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

    Returns:
        List[str]: è³ªå•é …ç›®ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ
    """
    # é™¤å¤–ã‚«ãƒ©ãƒ ã‚’ç‰¹å®š
    exclude_cols = set()

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ 
    for col in df.columns:
        if col in METADATA_COLUMNS:
            exclude_cols.add(col)

    # ç§‘ç›®åã‚«ãƒ©ãƒ 
    subject_col = detect_subject_column(df)
    if subject_col:
        exclude_cols.add(subject_col)

    # å‡ºå¸­ç•ªå·ã‚«ãƒ©ãƒ 
    student_id_col = detect_student_id_column(df)
    if student_id_col:
        exclude_cols.add(student_id_col)

    # è‡ªç”±è¨˜è¿°ã‚«ãƒ©ãƒ 
    free_text_col = detect_free_text_column(df)
    if free_text_col:
        exclude_cols.add(free_text_col)

    # è³ªå•é …ç›®ã‚«ãƒ©ãƒ ã‚’æŠ½å‡º
    question_cols = [col for col in df.columns if col not in exclude_cols]

    return question_cols


def load_and_process_csv(uploaded_file) -> Tuple[pd.DataFrame, Dict]:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‡¦ç†ã™ã‚‹

    Args:
        uploaded_file: Streamlitã®UploadedFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Returns:
        Tuple[pd.DataFrame, Dict]: å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’å–å¾—
    file_name = uploaded_file.name if hasattr(uploaded_file, 'name') else ''
    file_extension = file_name.lower().split('.')[-1] if '.' in file_name else ''

    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚’åˆ¤å®šã—ã¦èª­ã¿è¾¼ã¿
    if file_extension in ['xlsx', 'xls']:
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_excel(uploaded_file, engine='openpyxl')
    else:
        # CSVã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•åˆ¤å®šï¼‰
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(uploaded_file, encoding='shift-jis')
            except UnicodeDecodeError:
                df = pd.read_csv(uploaded_file, encoding='cp932')

    # ã‚«ãƒ©ãƒ æ¤œå‡º
    subject_col = detect_subject_column(df)
    student_id_col = detect_student_id_column(df)
    free_text_col = detect_free_text_column(df)
    question_cols = identify_question_columns(df)

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    metadata = {
        'subject_column': subject_col,
        'student_id_column': student_id_col,
        'free_text_column': free_text_col,
        'question_columns': question_cols,
        'total_responses': len(df),
    }

    return df, metadata


def calculate_statistics(df: pd.DataFrame, question_cols: List[str]) -> pd.DataFrame:
    """
    è³ªå•é …ç›®ã”ã¨ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        question_cols: è³ªå•é …ç›®ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ

    Returns:
        pd.DataFrame: çµ±è¨ˆæƒ…å ±ï¼ˆè³ªå•ã€å¹³å‡å€¤ã€å„ã‚¹ã‚³ã‚¢ã®å›ç­”æ•°ï¼‰
    """
    stats_list = []

    for question in question_cols:
        # ã‚¹ã‚³ã‚¢ã«å¤‰æ›
        scores = df[question].apply(convert_to_score)

        # æœ‰åŠ¹ãªå›ç­”æ•°
        valid_count = scores.notna().sum()

        if valid_count == 0:
            continue

        # å¹³å‡å€¤
        mean_score = scores.mean()

        # å„ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ
        score_counts = scores.value_counts().sort_index()
        count_4 = score_counts.get(4.0, 0)
        count_3 = score_counts.get(3.0, 0)
        count_2 = score_counts.get(2.0, 0)
        count_1 = score_counts.get(1.0, 0)

        stats_list.append({
            'è³ªå•é …ç›®': question,
            'å¹³å‡å€¤': mean_score,
            'æœ‰åŠ¹å›ç­”æ•°': valid_count,
            '4ç‚¹ã®å›ç­”æ•°': int(count_4),
            '3ç‚¹ã®å›ç­”æ•°': int(count_3),
            '2ç‚¹ã®å›ç­”æ•°': int(count_2),
            '1ç‚¹ã®å›ç­”æ•°': int(count_1),
        })

    return pd.DataFrame(stats_list)


def get_overall_average(df: pd.DataFrame, question_cols: List[str]) -> float:
    """
    å…¨è³ªå•ã®ç·åˆå¹³å‡ç‚¹ã‚’è¨ˆç®—

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        question_cols: è³ªå•é …ç›®ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ

    Returns:
        float: ç·åˆå¹³å‡ç‚¹
    """
    all_scores = []

    for question in question_cols:
        scores = df[question].apply(convert_to_score)
        all_scores.extend(scores.dropna().tolist())

    if len(all_scores) == 0:
        return 0.0

    return np.mean(all_scores)


def extract_free_comments(df: pd.DataFrame, free_text_col: str,
                         exclude_empty: bool = True) -> List[str]:
    """
    è‡ªç”±è¨˜è¿°ã‚’æŠ½å‡º

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        free_text_col: è‡ªç”±è¨˜è¿°ã‚«ãƒ©ãƒ å
        exclude_empty: ç©ºç™½ã‚„ã€Œç‰¹ã«ãªã—ã€ã‚’é™¤å¤–ã™ã‚‹ã‹

    Returns:
        List[str]: è‡ªç”±è¨˜è¿°ã®ãƒªã‚¹ãƒˆ
    """
    if not free_text_col or free_text_col not in df.columns:
        return []

    comments = df[free_text_col].tolist()

    if exclude_empty:
        # ç©ºç™½ã€NaNã€ã€Œç‰¹ã«ãªã—ã€ã€Œç‰¹ã«ã‚ã‚Šã¾ã›ã‚“ã€ãªã©ã‚’é™¤å¤–
        exclude_patterns = ['ç‰¹ã«ãªã—', 'ç‰¹ã«ã‚ã‚Šã¾ã›ã‚“', 'ãªã—', 'ç„¡ã—', '']
        comments = [
            str(c).strip() for c in comments
            if pd.notna(c) and str(c).strip() not in exclude_patterns
        ]

    return comments


def create_download_data(stats_df: pd.DataFrame, overall_avg: float,
                        subject_name: str = "å…¨ä½“") -> pd.DataFrame:
    """
    ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®Excelãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ

    Args:
        stats_df: çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        overall_avg: ç·åˆå¹³å‡ç‚¹
        subject_name: ç§‘ç›®å

    Returns:
        pd.DataFrame: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿
    """
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
    download_df = stats_df.copy()

    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    download_df['4ç‚¹ã®å‰²åˆ(%)'] = (
        download_df['4ç‚¹ã®å›ç­”æ•°'] / download_df['æœ‰åŠ¹å›ç­”æ•°'] * 100
    ).round(1)
    download_df['3ç‚¹ã®å‰²åˆ(%)'] = (
        download_df['3ç‚¹ã®å›ç­”æ•°'] / download_df['æœ‰åŠ¹å›ç­”æ•°'] * 100
    ).round(1)
    download_df['2ç‚¹ã®å‰²åˆ(%)'] = (
        download_df['2ç‚¹ã®å›ç­”æ•°'] / download_df['æœ‰åŠ¹å›ç­”æ•°'] * 100
    ).round(1)
    download_df['1ç‚¹ã®å‰²åˆ(%)'] = (
        download_df['1ç‚¹ã®å›ç­”æ•°'] / download_df['æœ‰åŠ¹å›ç­”æ•°'] * 100
    ).round(1)

    # å¹³å‡å€¤ã‚’å°æ•°ç‚¹2æ¡ã«ä¸¸ã‚ã‚‹
    download_df['å¹³å‡å€¤'] = download_df['å¹³å‡å€¤'].round(2)

    # ã‚«ãƒ©ãƒ ã®é †åºã‚’æ•´ç†
    download_df = download_df[[
        'è³ªå•é …ç›®',
        'å¹³å‡å€¤',
        'æœ‰åŠ¹å›ç­”æ•°',
        '4ç‚¹ã®å›ç­”æ•°',
        '4ç‚¹ã®å‰²åˆ(%)',
        '3ç‚¹ã®å›ç­”æ•°',
        '3ç‚¹ã®å‰²åˆ(%)',
        '2ç‚¹ã®å›ç­”æ•°',
        '2ç‚¹ã®å‰²åˆ(%)',
        '1ç‚¹ã®å›ç­”æ•°',
        '1ç‚¹ã®å‰²åˆ(%)',
    ]]

    return download_df


def write_to_template(df: pd.DataFrame, question_cols: List[str],
                     subject_mapping: Optional[Dict[str, List[str]]] = None,
                     placeholders: Optional[Dict[str, str]] = None,
                     template_path: str = "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ.xlsx") -> io.BytesIO:
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆExcelãƒ•ã‚¡ã‚¤ãƒ«ã«å„æ•™ç§‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€

    Args:
        df: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        question_cols: è³ªå•é …ç›®ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ
        subject_mapping: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸæ•™ç§‘ã¨ç§‘ç›®ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ•™ç§‘å -> ç§‘ç›®åãƒªã‚¹ãƒˆï¼‰
        placeholders: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆ{Y}, {n}, {MM}ãªã©ï¼‰ã¨ãã®å€¤
        template_path: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        BytesIO: æ›¸ãè¾¼ã¿æ¸ˆã¿Excelãƒ•ã‚¡ã‚¤ãƒ«
    """
    import openpyxl
    from openpyxl.utils import get_column_letter
    import re

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    wb = openpyxl.load_workbook(template_path)
    ws = wb['æ¦‚è¦']

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®6è¡Œç›®ã‹ã‚‰è³ªå•é …ç›®ã®åå‰ã‚’èª­ã¿è¾¼ã‚€ï¼ˆCåˆ—ã‹ã‚‰AFåˆ—ã¾ã§ï¼‰
    template_questions = []
    for col_idx in range(3, 33):  # Cåˆ—ï¼ˆ3ï¼‰ã‹ã‚‰AFåˆ—ï¼ˆ32ï¼‰ã¾ã§
        cell = ws.cell(row=6, column=col_idx)
        if cell.value:
            template_questions.append((col_idx, str(cell.value)))

    print(f"ğŸ” ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è³ªå•é …ç›®: {len(template_questions)}å€‹")

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›ã™ã‚‹é–¢æ•°
    def replace_placeholders(text):
        if placeholders and text:
            for key, value in placeholders.items():
                text = text.replace(f'{{{key}}}', str(value))
        return text

    # 1è¡Œç›®ã¨2è¡Œç›®ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
    for row_idx in [1, 2]:
        for col_idx in range(1, ws.max_column + 1):
            cell = ws.cell(row=row_idx, column=col_idx)
            if cell.value and isinstance(cell.value, str):
                cell.value = replace_placeholders(cell.value)

    # 7è¡Œç›®ã‹ã‚‰16è¡Œç›®ã®Båˆ—ï¼ˆè³ªå•é …ç›®åˆ—ï¼‰ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
    for row_idx in range(7, 17):
        cell = ws.cell(row=row_idx, column=2)  # Båˆ—
        if cell.value and isinstance(cell.value, str):
            cell.value = replace_placeholders(cell.value)

    # æ•™ç§‘åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¡Œç•ªå·ï¼‰
    subject_row_mapping = {
        'å…¨ä½“': 7,
        'å›½èª': 8,
        'æ•°å­¦': 9,
        'åœ°æ­´å…¬æ°‘': 10,
        'ç†ç§‘': 11,
        'å¤–å›½èª': 12,
        'ä¿å¥ä½“è‚²': 13,
        'èŠ¸è¡“': 14,
        'å®¶åº­': 15,
        'æƒ…å ±': 16,
    }

    # ç§‘ç›®ã‚«ãƒ©ãƒ ã‚’æ¤œå‡º
    subject_col = detect_subject_column(df)

    # å…¨ä½“ã®çµ±è¨ˆã‚’è¨ˆç®—
    overall_stats = calculate_statistics(df, question_cols)

    # ãƒ‡ãƒãƒƒã‚°: è³ªå•é …ç›®æ•°ã¨çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ± (write_to_template):")
    print(f"  - è³ªå•é …ç›®æ•°: {len(question_cols)}")
    print(f"  - çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®è¡Œæ•°: {len(overall_stats)}")
    print(f"  - è³ªå•é …ç›®ãƒªã‚¹ãƒˆ (æœ€åˆã®5å€‹): {question_cols[:5]}")
    if len(question_cols) > 30:
        print(f"  âš ï¸ è­¦å‘Š: è³ªå•é …ç›®ãŒ30å€‹ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ä½™åˆ†ãªé …ç›®:")
        print(f"    {question_cols[30:]}")

    # è³ªå•é …ç›®ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è³ªå•é …ç›®ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è³ªå•é …ç›®ã‚’ç…§åˆ
    question_mapping = {}  # {ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ—ç•ªå·: ãƒ‡ãƒ¼ã‚¿ã®è³ªå•é …ç›®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹}

    for template_col_idx, template_question in template_questions:
        matched = False

        # ã¾ãšå®Œå…¨ä¸€è‡´ã‚’æ¢ã™
        for data_idx, data_question in enumerate(question_cols):
            if data_question == template_question:
                question_mapping[template_col_idx] = data_idx
                matched = True
                break

        # å®Œå…¨ä¸€è‡´ãŒãªã„å ´åˆã€éƒ¨åˆ†ä¸€è‡´ã‚’è©¦ã™
        if not matched:
            for data_idx, data_question in enumerate(question_cols):
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè³ªå•ãŒãƒ‡ãƒ¼ã‚¿è³ªå•ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
                if template_question in data_question:
                    question_mapping[template_col_idx] = data_idx
                    matched = True
                    break
                # ãƒ‡ãƒ¼ã‚¿è³ªå•ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè³ªå•ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
                elif data_question in template_question:
                    question_mapping[template_col_idx] = data_idx
                    matched = True
                    break

    print(f"  - ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸè³ªå•é …ç›®: {len(question_mapping)}å€‹ / {len(template_questions)}å€‹")

    # ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œãªã‹ã£ãŸè³ªå•é …ç›®ã‚’è­¦å‘Š
    unmapped_template = [q for col_idx, q in template_questions if col_idx not in question_mapping]
    if unmapped_template:
        print(f"  âš ï¸ è­¦å‘Š: ä»¥ä¸‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè³ªå•é …ç›®ã«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ:")
        for q in unmapped_template[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
            print(f"    - {q}")
        if len(unmapped_template) > 5:
            print(f"    ... ä»–{len(unmapped_template) - 5}å€‹")

    # å…¨ä½“ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ï¼ˆ7è¡Œç›®ï¼‰
    row_idx = subject_row_mapping['å…¨ä½“']
    avg_values = overall_stats['å¹³å‡å€¤'].tolist()

    for template_col_idx, data_idx in question_mapping.items():
        if data_idx < len(avg_values):
            ws.cell(row=row_idx, column=template_col_idx, value=round(avg_values[data_idx], 2))

    # å„æ•™ç§‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦æ›¸ãè¾¼ã‚€
    if subject_col and subject_col in df.columns:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸãƒãƒƒãƒ”ãƒ³ã‚°ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if subject_mapping:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
            for template_subject, row_idx in subject_row_mapping.items():
                if template_subject == 'å…¨ä½“':
                    continue

                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸç§‘ç›®ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
                matched_subjects = subject_mapping.get(template_subject, [])

                # ãƒãƒƒãƒã—ãŸæ•™ç§‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if matched_subjects:
                    subject_df = df[df[subject_col].isin(matched_subjects)]

                    if len(subject_df) == 0:
                        continue

                    # çµ±è¨ˆã‚’è¨ˆç®—
                    subject_stats = calculate_statistics(subject_df, question_cols)

                    # ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ï¼ˆè³ªå•é …ç›®ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ï¼‰
                    avg_values = subject_stats['å¹³å‡å€¤'].tolist()
                    for template_col_idx, data_idx in question_mapping.items():
                        if data_idx < len(avg_values):
                            ws.cell(row=row_idx, column=template_col_idx, value=round(avg_values[data_idx], 2))
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è‡ªå‹•ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
            # æ•™ç§‘åã®éƒ¨åˆ†ä¸€è‡´ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            subject_keywords = {
                'å›½èª': ['å›½èª', 'ã“ãã”'],
                'æ•°å­¦': ['æ•°å­¦', 'ã™ã†ãŒã'],
                'åœ°æ­´å…¬æ°‘': ['åœ°ç†', 'æ­´å²', 'å…¬æ°‘', 'åœ°æ­´', 'ç¤¾ä¼š'],
                'ç†ç§‘': ['ç†ç§‘', 'ç‰©ç†', 'åŒ–å­¦', 'ç”Ÿç‰©', 'åœ°å­¦'],
                'å¤–å›½èª': ['è‹±èª', 'å¤–å›½èª', 'English'],
                'ä¿å¥ä½“è‚²': ['ä¿å¥', 'ä½“è‚²', 'ãŸã„ã„ã'],
                'èŠ¸è¡“': ['éŸ³æ¥½', 'ç¾è¡“', 'æ›¸é“', 'èŠ¸è¡“'],
                'å®¶åº­': ['å®¶åº­', 'ã‹ã¦ã„'],
                'æƒ…å ±': ['æƒ…å ±', 'ã˜ã‚‡ã†ã»ã†'],
            }

            # ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹æ•™ç§‘åã‚’å–å¾—
            unique_subjects = df[subject_col].unique()

            # å„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ•™ç§‘ã«ã¤ã„ã¦å‡¦ç†
            for template_subject, row_idx in subject_row_mapping.items():
                if template_subject == 'å…¨ä½“':
                    continue

                # éƒ¨åˆ†ä¸€è‡´ã§æ•™ç§‘ã‚’æ¤œç´¢
                matched_subjects = []
                keywords = subject_keywords.get(template_subject, [])

                for actual_subject in unique_subjects:
                    if pd.isna(actual_subject):
                        continue

                    actual_subject_str = str(actual_subject)

                    # å®Œå…¨ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
                    if actual_subject_str == template_subject:
                        matched_subjects.append(actual_subject)
                        continue

                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹éƒ¨åˆ†ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
                    for keyword in keywords:
                        if keyword in actual_subject_str:
                            matched_subjects.append(actual_subject)
                            break

                # ãƒãƒƒãƒã—ãŸæ•™ç§‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if matched_subjects:
                    subject_df = df[df[subject_col].isin(matched_subjects)]

                    if len(subject_df) == 0:
                        continue

                    # çµ±è¨ˆã‚’è¨ˆç®—
                    subject_stats = calculate_statistics(subject_df, question_cols)

                    # ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ï¼ˆè³ªå•é …ç›®ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ï¼‰
                    avg_values = subject_stats['å¹³å‡å€¤'].tolist()
                    for template_col_idx, data_idx in question_mapping.items():
                        if data_idx < len(avg_values):
                            ws.cell(row=row_idx, column=template_col_idx, value=round(avg_values[data_idx], 2))

    # BytesIOã«æ›¸ãè¾¼ã¿
    output = io.BytesIO()
    wb.save(output)
    output.seek(0)

    return output
